{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 - Ordinary Least Squares (20 Points)\n",
    "\n",
    "The first exercise is about linear models.\n",
    "The given data set contains prices and other attributes of approximately 54,000 diamonds. You should fit a linear model to predict the price of a diamond, given its attributes.\n",
    "\n",
    "This exercise is meant to get you started with the tool stack. Besides numpy and matplotlib we use the following python packages:\n",
    "\n",
    "- [pandas](https://pandas.pydata.org/)\n",
    "- [sklearn](http://scikit-learn.org/)\n",
    "\n",
    "If you are unfamiliar with them, follow the documentation links. In the event of a persistent problem, do not hesitate to contact the course instructors.\n",
    "\n",
    "- christoph.staudt@uni-jena.de\n",
    "\n",
    "### Submission\n",
    "\n",
    "- Deadline of submission:\n",
    "        28.04.2021 23:59\n",
    "- Submission on [moodle page](https://moodle.uni-jena.de/course/view.php?id=28746)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "We use the same notation as in the lecture.\n",
    "- $m$... Number of datapoints\n",
    "- $n$... Number of features\n",
    "\n",
    "### Dataset \n",
    "\n",
    "As a dataset, we use the famous [diamond dataset](https://www.kaggle.com/shivam2503/diamonds).\n",
    "\n",
    "Each element in this dataset represents a diamond and has the following features:\n",
    "\n",
    "- price: price in US dollars (326.0 - 18823.0)\n",
    "- carat: weight of the diamond (0.2 - 5.01)\n",
    "- cut: quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n",
    "- color: diamond colour, from J (worst) to D (best)\n",
    "- clarity: a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n",
    "- x: length in mm (0-10.74)\n",
    "- y: width in mm (0-58.9)\n",
    "- z: depth in mm (0-31.8)\n",
    "- depth: total depth percentage = 2 * z / (x + y) (43-79)\n",
    "- table: width of top of diamond relative to widest point (43-95)\n",
    "\n",
    "The dataset is stored under `diamonds.csv`.\n",
    "\n",
    "### Task 1 (1 Point)\n",
    "Import the data from the file using [pandas](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) and examine it.\n",
    "\n",
    "Determine the following:\n",
    "\n",
    "* The number of data points\n",
    "* The column names\n",
    "* The data types for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data points:\n",
      "539400\n",
      "\n",
      "column names:\n",
      "['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y', 'z']\n",
      "\n",
      "data types:\n",
      "{'carat': dtype('float64'), 'cut': dtype('O'), 'color': dtype('O'), 'clarity': dtype('O'), 'depth': dtype('float64'), 'table': dtype('float64'), 'price': dtype('int64'), 'x': dtype('float64'), 'y': dtype('float64'), 'z': dtype('float64')}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"diamonds.csv\")\n",
    "m = df.size\n",
    "columns = list(df.columns)\n",
    "dtypes = dict(df.dtypes)\n",
    "print(f\"number of data points:\\n{m}\\n\\ncolumn names:\\n{columns}\\n\\ndata types:\\n{dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (1 Point)\n",
    "\n",
    "Since there are discrete variables and we do not yet know how to include them into our regression model, remove them. Additionally, verify that there are no missing values in our dataset.\n",
    "\n",
    "Hint: there are multiple ways to [check](https://towardsdatascience.com/how-to-check-for-missing-values-in-pandas-d2749e45a345) for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed: ['cut', 'color', 'clarity']\n",
      "remaining: ['carat', 'depth', 'table', 'price', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "removed_columns = [column for column in df.columns if df.dtypes[column] == object]\n",
    "df = df.drop(columns=removed_columns)\n",
    "assert not df.isna().any().any()\n",
    "\n",
    "print(f\"removed: {removed_columns}\")\n",
    "print(f\"remaining: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the lecture, we should **standardize** the data, to make different scales comparable.\n",
    "\n",
    "Standardization is defined for each feature $x_i$:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{x}_i = \\cfrac{x_i-\\mu_x}{\\sigma_x}\\,,\n",
    "\\end{align}\n",
    "where $\\mu_x$ and $\\sigma_x$ are the empirical [mean](https://en.wikipedia.org/wiki/Mean) and [standard deviation](https://en.wikipedia.org/wiki/Standard_deviation) of the feature $x$.\n",
    "\n",
    "### Task 3 (2 Points)\n",
    "\n",
    "Convert the pandas dataframe to a numpy array and calculate the standardized data matrix $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.19816781 -0.17409151 -1.09967199 ... -1.58783745 -1.53619556\n",
      "  -1.57112919]\n",
      " [-1.24036129 -1.36073849  1.58552871 ... -1.64132529 -1.65877419\n",
      "  -1.74117497]\n",
      " [-1.19816781 -3.38501862  3.37566251 ... -1.49869105 -1.45739502\n",
      "  -1.74117497]\n",
      " ...\n",
      " [-0.20662095  0.73334442  1.13799526 ... -0.06343409 -0.04774083\n",
      "   0.03013526]\n",
      " [ 0.13092691 -0.52310533  0.24292836 ...  0.37338325  0.33750627\n",
      "   0.28520393]\n",
      " [-0.10113725  0.31452784 -1.09967199 ...  0.08811478  0.11861587\n",
      "   0.14349912]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "view = df.to_numpy()\n",
    "mean = np.mean(view, axis=0)\n",
    "std = np.std(view, axis=0)\n",
    "view = (view - mean) / std\n",
    "print(view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 (2 Points)\n",
    "\n",
    "Scikit learn has an [implementation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) of this preprocessing.\n",
    "\n",
    "Use it to create a second standardized data matrix and compare this result with your result from Task 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# should i use scaler.fit_transform(df) here?\n",
    "scaler.fit(df)\n",
    "transformed = scaler.transform(df)\n",
    "# see where this differs from our own implementation\n",
    "diff = transformed - view\n",
    "print(diff[diff > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 (2 Points)\n",
    "\n",
    "Visualizing correlation in your data often helps to build intuition and get a feeling of the deeper mojo in the set.\n",
    "\n",
    "Here we want to use the [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) as a measure for correlation between two variables.\n",
    "\n",
    "Let $x$ and $y$ be two variables of the unstandardized dataset (e.g. `carat` and `price`). The empirical Pearson correlation coefficient between $x$ and $y$ is defined as \n",
    "\n",
    "\\begin{align}\n",
    "r_{xy} = \\cfrac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^n(y_i-\\bar{y})^2}}\\,,\n",
    "\\end{align}\n",
    "where $\\bar{x}$ and $\\bar{y}$ are the respective empirical means.\n",
    "\n",
    "---\n",
    "\n",
    "How does this definition translate to our standardized data matrix $X$?\n",
    "\n",
    "Calculate the pairwise correlation matrix for our dataset. \n",
    "\n",
    "Visualize this correlation matrix and label the rows/columns. Using [imshow](https://matplotlib.org/3.5.0/api/_as_gen/matplotlib.pyplot.imshow.html?highlight=imshow) with a color map produces nice results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: calculate correlation matrix\n",
    "\n",
    "# TODO: Visualize correlation matrix and label the rows / columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "The goal is to predict the `price` of a diamond based on some of its other features.\n",
    "\n",
    "### Task 6 (1 Point)\n",
    "Make a scatter plot of `carat` vs `price` using Matplotlib. Label the axes and give the plot a title.\n",
    "\n",
    "Use the standardized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: display data in scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 (4 Points)\n",
    "\n",
    "Implement a `LinReg` class, that uses maximum likelihood estimation (see the lecture script) to estimate $\\theta$. Add the possibility to use [Ridge Regression](https://en.wikipedia.org/wiki/Ridge_regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReg():\n",
    "    \n",
    "    def __init__(self, c=0):\n",
    "        # TODO: create attributes c (for ridge regression), theta (model parameters)\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        # TODO: estimate theta\n",
    "        pass\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # TODO: predict labels\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8 (2 Points)\n",
    "\n",
    "Here you want to predict the `price` of a diamond solely from the variable `carat`. \n",
    "Set up the design matrix for this case and use your class to estimate $\\theta$ on the dataset.\n",
    "Note, that the design matrix does **not** need the vector of ones, since we standardized the dataset.\n",
    "\n",
    "Plot the regression line defined by $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: build design matrix, y\n",
    "\n",
    "# TODO: use Linear Regression\n",
    "\n",
    "# TODO: plot data + regression line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9 (2 Points)\n",
    "\n",
    "You can find an implementation of this method in the python module [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html). Use it and compare your result for the estimation of $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use scikit learn to estimate theta\n",
    "\n",
    "# TODO: compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10 (3 Points)\n",
    "\n",
    "Now predict the `price` from the variables `carat`, `depth`, `table`, `x`, `y`, `z`.\n",
    "\n",
    "- Estimate $\\theta$ with your class\n",
    "- Estimate $\\theta$ with scikit learn\n",
    "- Compare both estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: build X, Y\n",
    "\n",
    "# TODO: estimate theta\n",
    "\n",
    "# TODO: estimate theta using scikit-learn + compare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
